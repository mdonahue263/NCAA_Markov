{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2/26 - going to try to re calculate St Johns so we can understand why it's all 0s\n",
    "#issue was it was trying to regex match parentheses. now will search for parentheses and replace with escape characters and should work.\n",
    "#2/26 - need to exclude invalid transitions from individual team stats too\n",
    "#in v02, we might try to save individual team time distributions too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from helper_functions.clean_transitions import clean_transition_column\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_transitions(transition_df):\n",
    "    #delete all transitions from FREETHROW state that don't result in either team r or opposite team i\n",
    "    #also delete when freethrow turns to i2 or i3\n",
    "    validate = []\n",
    "    for i in range(len(transition_df)):\n",
    "        curr_tran = transition_df['Transition'][i]\n",
    "        if curr_tran in [('Bi1', 'Af3'),\n",
    "                        ('Ai2', 'Bf3'),\n",
    "                        ('Af0', 'Af3'),\n",
    "                        ('Ai0', 'Bf3'),\n",
    "                        ('Bf2', 'Bf2'),\n",
    "                        ('Bi3', 'Af3'),\n",
    "                        ('Ai0', 'Bf2'),\n",
    "                        ('Bf3', 'Bf0'),\n",
    "                        ('Af3', 'Af1'),\n",
    "                        ('Af3', 'Af0'),\n",
    "                        ('Bf0', 'Bf2'),\n",
    "                        ('Bf3', 'Bf1'),\n",
    "                        ('Ai1', 'Bf3'),\n",
    "                        ('Br0', 'Af3'),\n",
    "                        ('Ar0', 'Bf3'),\n",
    "                        ('Af0', 'Af2'),\n",
    "                        ('Ai3', 'Bf2'),\n",
    "                        ('Bi3', 'Af2'),\n",
    "                        ('Bf2', 'Bf1'),\n",
    "                        ('Bf2', 'Bf0'),\n",
    "                        ('Ai2', 'Bf2'),\n",
    "                        ('Ai1', 'Bf2'),\n",
    "                        ('Af2', 'Af1'),\n",
    "                        ('Bi0', 'Af2'),\n",
    "                        ('Bi2', 'Af2'),\n",
    "                        ('Af2', 'Af0'),\n",
    "                        ('Bi1', 'Af2'),\n",
    "                        ('Bi3', 'Bi3'),\n",
    "                        ('Ai3', 'Ai3'),\n",
    "                        ('Ai0', 'Ai3'),\n",
    "                        ('Bi0', 'Bi3'),\n",
    "                        ('Ai2', 'Ai3'),\n",
    "                        ('Ai3', 'Ai2'),\n",
    "                        ('Ai3', 'Bf0'),\n",
    "                        ('Br0', 'Af2'),\n",
    "                        ('Ar0', 'Bf2'),\n",
    "                        ('Ai1', 'Ai3'),\n",
    "                        ('Bi3', 'Af0'),\n",
    "                        ('Bi0', 'Af0'),\n",
    "                        ('Ai0', 'Ai2'),\n",
    "                        ('Ai1', 'Bf0'),\n",
    "                        ('Bi3', 'Bi2'),\n",
    "                        ('Ai0', 'Bf0'),\n",
    "                        ('Ai2', 'Ai2'),\n",
    "                        ('Bi1', 'Bi3'),\n",
    "                        ('Bi0', 'Bi2'),\n",
    "                        ('Bi2', 'Bi3'),\n",
    "                        ('Bi1', 'Af0'),\n",
    "                        ('Br0', 'Bi3'),\n",
    "                        ('Ai1', 'Ai2'),\n",
    "                        ('Bi2', 'Bi2'),\n",
    "                        ('Bi1', 'Bi2'),\n",
    "                        ('Ai2', 'Bf0'),\n",
    "                        ('Ar0', 'Ai3'),\n",
    "                        ('Bi2', 'Af0'),\n",
    "                        ('Br0', 'Bi2'),\n",
    "                        ('Br0', 'Af0'),\n",
    "                        ('Ar0', 'Ai2'),\n",
    "                        ('Ar0', 'Bf0'),\n",
    "                        ('Bi2','Af3'),\n",
    "                        ('Af3','Af2')]:\n",
    "            validate.append(False)\n",
    "\n",
    "        elif ('f' in curr_tran[0])&('f' in curr_tran[1]):\n",
    "            if (('A' in curr_tran[0])&('A' in curr_tran[1])) | (('B' in curr_tran[0])&('B' in curr_tran[1])):\n",
    "                validate.append(True)\n",
    "            else:\n",
    "                validate.append(False)\n",
    "        elif (('Af' in curr_tran[0])&('Ai' in curr_tran[1])) | (('Bf' in curr_tran[0])&('Bi' in curr_tran[1])):\n",
    "            validate.append(False)\n",
    "        elif ('f' in curr_tran[0])&(('i3' in curr_tran[1]) | ('i2' in curr_tran[1])):\n",
    "            validate.append(False)\n",
    "        elif ('1' in curr_tran[1])&('f' not in curr_tran[0]):\n",
    "            validate.append(False)\n",
    "        else:\n",
    "            validate.append(True)\n",
    "    return validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_states = ['Ai0',\n",
    "'Ai1',\n",
    "'Ai2',\n",
    "'Ai3',\n",
    "'Ar0',\n",
    "'Af0',\n",
    "'Af1',\n",
    "'Af2',\n",
    "'Af3',\n",
    "'Bi0',\n",
    "'Bi1',\n",
    "'Bi2',\n",
    "'Bi3',\n",
    "'Br0',\n",
    "'Bf0',\n",
    "'Bf1',\n",
    "'Bf2',\n",
    "'Bf3']\n",
    "\n",
    "possible_transitions = list(product(possible_states,possible_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_excel('ALL_VALID_TRANSITIONS_v03.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.read_csv('ALL_VALID_TRANSITIONS_v04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data = pd.read_excel('Team_Names_Abbrs_v02.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_times = pd.read_excel('All_Transition_With_Times_Not_Aggregated_v04.xlsx')\n",
    "# transition_times['Transition'] = clean_transition_column(transition_times['Transition'])\n",
    "unique_valid_trans = data2['Transition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some basic ground rules - any F to F transition should be 0 seconds\n",
    "unique_trans = transition_times['Transition'].unique()\n",
    "for t in unique_trans:\n",
    "    if (('f' in t[0]) & ('f' in t[1]))|(t not in list(unique_valid_trans)):\n",
    "        transition_times.loc[transition_times['Transition'] == t, 'Time'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_saved = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680 [04:27<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "#need to do this for each team twice - once as team A, once as team B\n",
    "\n",
    "for m in tqdm(team_data['name']):\n",
    "    n = m.replace('(', ('\\(')).replace(')','\\)')\n",
    "\n",
    "    if n in teams_saved:\n",
    "        raise Exception('Collision on {}!'.format(n))\n",
    "\n",
    "    #one copy of smaller dataset for each A and B\n",
    "    shrink_data_a = data[data['filename'].str.contains(n)].copy().reset_index(drop=True)\n",
    "    shrink_data_b = shrink_data_a.copy()\n",
    "\n",
    "    #ADDING LOGIC TO GET TEAM-SPECIFIC TIME DISTRIBUTION\n",
    "    shrink_time_a = transition_times[transition_times['filename'].str.contains(n)].copy().reset_index(drop=True)\n",
    "    shrink_time_b = shrink_time_a.copy()\n",
    "\n",
    "    unique_games = shrink_data_a['filename'].unique()\n",
    "    games_count = len(unique_games)\n",
    "    #ignore this if - this was earlier for testing\n",
    "    if games_count <= 100:\n",
    "        for fname in unique_games:\n",
    "\n",
    "            #team A\n",
    "            if fname.find(n)>fname.find('vs'):\n",
    "                shrink_data_a.loc[shrink_data_a['filename']==fname, 'Transition'] = shrink_data_a.loc[shrink_data_a['filename']==fname, 'Transition'].str.replace('A','TEMP')\n",
    "                shrink_data_a.loc[shrink_data_a['filename']==fname, 'Transition'] = shrink_data_a.loc[shrink_data_a['filename']==fname, 'Transition'].str.replace('B','A')\n",
    "                shrink_data_a.loc[shrink_data_a['filename']==fname, 'Transition'] = shrink_data_a.loc[shrink_data_a['filename']==fname, 'Transition'].str.replace('TEMP','B')\n",
    "                #same logic for time df\n",
    "                shrink_time_a.loc[shrink_time_a['filename']==fname, 'Transition'] = shrink_time_a.loc[shrink_time_a['filename']==fname, 'Transition'].str.replace('A','TEMP')\n",
    "                shrink_time_a.loc[shrink_time_a['filename']==fname, 'Transition'] = shrink_time_a.loc[shrink_time_a['filename']==fname, 'Transition'].str.replace('B','A')\n",
    "                shrink_time_a.loc[shrink_time_a['filename']==fname, 'Transition'] = shrink_time_a.loc[shrink_time_a['filename']==fname, 'Transition'].str.replace('TEMP','B')\n",
    "\n",
    "            #team B\n",
    "            if fname.find(n)<fname.find('vs'):\n",
    "                shrink_data_b.loc[shrink_data_b['filename']==fname, 'Transition'] = shrink_data_b.loc[shrink_data_b['filename']==fname, 'Transition'].str.replace('A','TEMP')\n",
    "                shrink_data_b.loc[shrink_data_b['filename']==fname, 'Transition'] = shrink_data_b.loc[shrink_data_b['filename']==fname, 'Transition'].str.replace('B','A')\n",
    "                shrink_data_b.loc[shrink_data_b['filename']==fname, 'Transition'] = shrink_data_b.loc[shrink_data_b['filename']==fname, 'Transition'].str.replace('TEMP','B')\n",
    "                #same logic for time df\n",
    "                shrink_time_b.loc[shrink_time_b['filename']==fname, 'Transition'] = shrink_time_b.loc[shrink_time_b['filename']==fname, 'Transition'].str.replace('A','TEMP')\n",
    "                shrink_time_b.loc[shrink_time_b['filename']==fname, 'Transition'] = shrink_time_b.loc[shrink_time_b['filename']==fname, 'Transition'].str.replace('B','A')\n",
    "                shrink_time_b.loc[shrink_time_b['filename']==fname, 'Transition'] = shrink_time_b.loc[shrink_time_b['filename']==fname, 'Transition'].str.replace('TEMP','B')\n",
    "\n",
    "        #now clean transition column\n",
    "        shrink_data_a['Transition']=clean_transition_column(shrink_data_a['Transition'])\n",
    "        shrink_data_b['Transition']=clean_transition_column(shrink_data_b['Transition'])\n",
    "\n",
    "        #same for time df\n",
    "        shrink_time_a['Transition']=clean_transition_column(shrink_time_a['Transition'])\n",
    "        shrink_time_b['Transition']=clean_transition_column(shrink_time_b['Transition'])\n",
    "\n",
    "        #need to validate transitions too\n",
    "        shrink_data_a['valid_tran'] = validate_transitions(shrink_data_a)\n",
    "        shrink_data_a=shrink_data_a[shrink_data_a['valid_tran']==True].copy().reset_index(drop=True)\n",
    "        shrink_data_a=shrink_data_a.drop('valid_tran',axis=1)\n",
    "\n",
    "        shrink_time_a['valid_tran'] = validate_transitions(shrink_time_a)\n",
    "        shrink_time_a=shrink_time_a[shrink_time_a['valid_tran']==True].copy().reset_index(drop=True)\n",
    "        shrink_time_a=shrink_time_a.drop('valid_tran',axis=1)\n",
    "\n",
    "        shrink_data_b['valid_tran'] = validate_transitions(shrink_data_b)\n",
    "        shrink_data_b=shrink_data_b[shrink_data_b['valid_tran']==True].copy().reset_index(drop=True)\n",
    "        shrink_data_b=shrink_data_b.drop('valid_tran',axis=1)\n",
    "\n",
    "        shrink_time_b['valid_tran'] = validate_transitions(shrink_time_b)\n",
    "        shrink_time_b=shrink_time_b[shrink_time_b['valid_tran']==True].copy().reset_index(drop=True)\n",
    "        shrink_time_b=shrink_time_b.drop('valid_tran',axis=1)\n",
    "\n",
    "\n",
    "        #group and count transitions\n",
    "        transitions_agg_a = shrink_data_a.groupby('Transition')['Period'].count().reset_index()\n",
    "        transitions_agg_b = shrink_data_b.groupby('Transition')['Period'].count().reset_index()\n",
    "\n",
    "        #add zero counts for the rest of the transitions for completeness\n",
    "        for t in possible_transitions:\n",
    "            if t not in list(transitions_agg_a['Transition'].values):\n",
    "                curr_row = pd.DataFrame([[t, 0]], columns=['Transition','Period'])\n",
    "                transitions_agg_a=pd.concat([transitions_agg_a,curr_row])\n",
    "\n",
    "            if t not in list(transitions_agg_b['Transition'].values):\n",
    "                curr_row = pd.DataFrame([[t, 0]], columns=['Transition','Period'])\n",
    "                transitions_agg_b=pd.concat([transitions_agg_b,curr_row])\n",
    "\n",
    "        #rename column to Count\n",
    "        transitions_agg_a = transitions_agg_a.rename(columns={'Period':'Count'})\n",
    "        transitions_agg_b = transitions_agg_b.rename(columns={'Period':'Count'})\n",
    "\n",
    "        #starting state and ending state columns for easier pivot\n",
    "        transitions_agg_a['Starting_State'] = [x[0] for x in transitions_agg_a['Transition']]\n",
    "        transitions_agg_a['Ending_State'] = [x[1] for x in transitions_agg_a['Transition']]\n",
    "\n",
    "        transitions_agg_b['Starting_State'] = [x[0] for x in transitions_agg_b['Transition']]\n",
    "        transitions_agg_b['Ending_State'] = [x[1] for x in transitions_agg_b['Transition']]\n",
    "\n",
    "        #take only necessary columns\n",
    "        transitions_agg_a=transitions_agg_a[['Starting_State','Ending_State','Count']]\n",
    "        transitions_agg_b=transitions_agg_b[['Starting_State','Ending_State','Count']]\n",
    "\n",
    "        #pivot\n",
    "        transition_matrix_a = transitions_agg_a.pivot(index='Starting_State', columns='Ending_State', values='Count').fillna(0)\n",
    "        transition_matrix_b = transitions_agg_b.pivot(index='Starting_State', columns='Ending_State', values='Count').fillna(0)\n",
    "\n",
    "        #divide along horizontal axis for total probability of 1\n",
    "        transition_matrix_a = transition_matrix_a.div(transition_matrix_a.sum(axis=1), axis=0)\n",
    "        transition_matrix_b = transition_matrix_b.div(transition_matrix_b.sum(axis=1), axis=0)\n",
    "\n",
    "        #kill na's \n",
    "        transition_matrix_a=transition_matrix_a.fillna(0)\n",
    "        transition_matrix_b=transition_matrix_b.fillna(0)\n",
    "\n",
    "        transition_matrix_a.to_excel('team_specific_matrix/{}_A.xlsx'.format(m))\n",
    "        transition_matrix_b.to_excel('team_specific_matrix/{}_B.xlsx'.format(m))\n",
    "\n",
    "        #now process time df\n",
    "        #find interquartile range of each transition's time durations\n",
    "        quartiles_a = shrink_time_a.groupby('Transition')['Time'].quantile([0.1, 0.9]).unstack()\n",
    "        quartiles_b = shrink_time_b.groupby('Transition')['Time'].quantile([0.1, 0.9]).unstack()\n",
    "\n",
    "        #merge original DF with interquartile range df to filter\n",
    "        df_merged_a = pd.merge(shrink_time_a, quartiles_a, left_on='Transition', right_index=True, suffixes=('', '_quartile'))\n",
    "        df_merged_b = pd.merge(shrink_time_b, quartiles_b, left_on='Transition', right_index=True, suffixes=('', '_quartile'))\n",
    "\n",
    "        filtered_df_a = df_merged_a[(df_merged_a['Time'] >= df_merged_a[0.1]) & (df_merged_a['Time'] <= df_merged_a[0.9])]\n",
    "        filtered_df_b = df_merged_b[(df_merged_b['Time'] >= df_merged_b[0.1]) & (df_merged_b['Time'] <= df_merged_b[0.9])]\n",
    "        \n",
    "        smaller_ranged_times_a = filtered_df_a[['Transition','Time']].copy()\n",
    "        smaller_ranged_times_b = filtered_df_b[['Transition','Time']].copy()\n",
    "\n",
    "        new_df_a = pd.DataFrame()\n",
    "        for t in tqdm(smaller_ranged_times_a['Transition'].unique()):\n",
    "            temp_df = smaller_ranged_times_a[smaller_ranged_times_a['Transition']==t].groupby('Time').count().reset_index()\n",
    "            temp_df['Freq'] = temp_df['Transition']/temp_df['Transition'].sum()\n",
    "            temp_df['Transition']=str(t)\n",
    "            temp_df=temp_df[['Transition','Time','Freq']].copy()\n",
    "            new_df_a=pd.concat([new_df_a, temp_df]).reset_index(drop=True)\n",
    "\n",
    "        new_df_b = pd.DataFrame()\n",
    "        for t in tqdm(smaller_ranged_times_b['Transition'].unique()):\n",
    "            temp_df = smaller_ranged_times_b[smaller_ranged_times_b['Transition']==t].groupby('Time').count().reset_index()\n",
    "            temp_df['Freq'] = temp_df['Transition']/temp_df['Transition'].sum()\n",
    "            temp_df['Transition']=str(t)\n",
    "            temp_df=temp_df[['Transition','Time','Freq']].copy()\n",
    "            new_df_b=pd.concat([new_df_b, temp_df]).reset_index(drop=True)\n",
    "\n",
    "        new_df_a['Transition']=clean_transition_column(new_df_a['Transition'])\n",
    "        new_df_b['Transition']=clean_transition_column(new_df_b['Transition'])\n",
    "\n",
    "        new_df_a.to_excel('team_specific_times/{}_A.xlsx'.format(m))\n",
    "        new_df_b.to_excel('team_specific_times/{}_B.xlsx'.format(m))\n",
    "\n",
    "        teams_saved.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
